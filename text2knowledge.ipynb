{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology-Aware Knowledge Extraction: From Text to Knowledge Graph\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **ontology-driven entity extraction** using large language models (LLMs) to transform unstructured text into structured RDF knowledge graphs. Unlike traditional Named Entity Recognition (NER) systems, this approach leverages the semantic understanding of modern LLMs combined with formal ontologies to achieve **concept-aware extraction**.\n",
    "\n",
    "## The Challenge: Ambiguous Terms in Unstructured Text\n",
    "\n",
    "The corpus (`jaguar_corpus.txt`) contains information about multiple entities that share the word \"Jaguar\":\n",
    "- üêÜ **Wildlife jaguars** (Panthera onca) - the big cat species\n",
    "- üöó **Jaguar cars** (E-Type, XK-E) - luxury automobiles\n",
    "- üé∏ **Fender Jaguar** - electric guitars\n",
    "\n",
    "Traditional keyword-based extraction would indiscriminately extract all \"Jaguar\" mentions, creating noise and confusion in our knowledge graph.\n",
    "\n",
    "## The Solution: Ontology-Driven Knowledge Representation\n",
    "\n",
    "By providing the LLM with our **jaguar conservation ontology** (`jaguar_ontology.ttl`), the model understands:\n",
    "- The **domain context** (wildlife conservation)\n",
    "- The **class hierarchy** (Jaguar ‚Üí Animal ‚Üí Species)\n",
    "- The **properties and relationships** (hasGender, occursIn, monitoredByOrg)\n",
    "- The **semantic structure** of our knowledge domain\n",
    "\n",
    "The LLM uses this ontological understanding to:\n",
    "1. **Filter relevant entities** - Only extract wildlife-related jaguars\n",
    "2. **Recognize relationships** - Identify connections between jaguars, locations, organizations, threats\n",
    "3. **Generate aligned RDF** - Produce Turtle syntax that perfectly matches our ontology structure\n",
    "4. **Infer implicit relationships** - Connect entities based on contextual understanding\n",
    "\n",
    "## Knowledge Graphs vs. Traditional Databases\n",
    "\n",
    "**Knowledge Graphs (RDF/SPARQL)** enable:\n",
    "- **Formal ontologies** that define domain semantics\n",
    "- **Schema flexibility** with open-world assumptions\n",
    "- **Reasoning capabilities** through RDFS/OWL inference\n",
    "- **Semantic interoperability** across datasets\n",
    "- **Context-aware querying** with SPARQL\n",
    "\n",
    "This notebook showcases how ontologies transform LLMs from simple text processors into **semantic knowledge miners** that understand concepts, not just patterns.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin by setting up our environment and loading the necessary data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize OpenAI Client\n",
    "\n",
    "First, we initialize the OpenAI client with API credentials from our environment variables. This notebook uses **GPT-5** (or GPT-4o as fallback) for its advanced reasoning capabilities and deep semantic understanding.\n",
    "\n",
    "The model needs to:\n",
    "- Understand complex ontology structures\n",
    "- Parse relationships and properties\n",
    "- Generate valid RDF Turtle syntax\n",
    "- Reason about entity disambiguation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize the OpenAI client \n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    " )\n",
    "\n",
    "print(\"OpenAI client initialized successfully!\")\n",
    "\n",
    "# Make a call to the OpenAI client\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a coding joke\"}\n",
    " ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENAI_RESPONSES_MODEL_ID\", \"gpt-4o\"),\n",
    "    messages=messages\n",
    " )\n",
    "\n",
    "# Print the response content\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Jaguar Conservation Ontology\n",
    "\n",
    "We load the **formal ontology** that defines our domain model. This ontology contains:\n",
    "\n",
    "- **Classes**: `Jaguar`, `Habitat`, `ConservationEffort`, `Organization`, `Threat`, etc.\n",
    "- **Properties**: `hasGender`, `occursIn`, `monitoredByOrg`, `facesThreat`, etc.\n",
    "- **Relationships**: How entities connect (e.g., jaguars ‚Üí locations ‚Üí organizations)\n",
    "- **Data types**: String labels, dates, boolean values, etc.\n",
    "\n",
    "The ontology serves as the **semantic blueprint** that guides the LLM's extraction process. It defines what concepts are relevant to our domain and how they should be structured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/jaguar_ontology.ttl'\n",
    "with open(file_path, 'r') as f:\n",
    "    ontology = f.read()\n",
    "\n",
    "print(f\"Successfully loaded ontology from {file_path}. Content length: {len(ontology)} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the Text Corpus\n",
    "\n",
    "Now we load the unstructured text corpus containing mixed content about:\n",
    "- **Wildlife jaguars**: Conservation efforts, individual animals (El Jefe, Macho B), habitats, threats\n",
    "- **Jaguar cars**: E-Type models, specifications, history\n",
    "- **Fender Jaguar guitars**: Musical instruments, production details\n",
    "\n",
    "This mixed-content corpus simulates a real-world scenario where domain-specific information is embedded within noisy, multi-domain text sources.\n",
    "\n",
    "**The key question**: How do we extract ONLY the wildlife-related information while ignoring cars and guitars?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/jaguar_corpus.txt'\n",
    "with open(file_path, 'r') as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "print(f\"Successfully loaded text from {file_path}. Content length: {len(corpus)} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Ontology-Aware Extraction with GPT-5\n",
    "\n",
    "### The Magic: Concept Understanding Through Formal Semantics\n",
    "\n",
    "This is where **ontology-driven extraction** happens. We provide GPT-5 with:\n",
    "1. The **ontology** (semantic structure)\n",
    "2. The **corpus** (unstructured text)\n",
    "3. Instructions to extract entities and relationships that **align with the ontology**\n",
    "\n",
    "### What Makes This Intelligent?\n",
    "\n",
    "The LLM doesn't just pattern-match \"jaguar\" keywords. Instead, it:\n",
    "- **Understands the domain** from the ontology classes and properties\n",
    "- **Disambiguates entities** based on semantic context (wildlife vs. cars vs. guitars)\n",
    "- **Extracts ONLY relevant information** about wildlife jaguars\n",
    "- **Generates valid RDF Turtle** that conforms to our ontology structure\n",
    "- **Infers relationships** between entities based on contextual clues\n",
    "\n",
    "### Processing Time\n",
    "\n",
    "‚è±Ô∏è **Expected duration**: 2-4 minutes (GPT-5 uses high reasoning effort for deep semantic analysis)\n",
    "\n",
    "### Output\n",
    "\n",
    "The result will be **RDF Turtle code** that can be directly imported into GraphDB using \"Import ‚Üí Text snippet\". The data will beautifully align with your ontology, creating a semantically rich knowledge graph ready for SPARQL queries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Given this ontology: \n",
    "{ontology}\n",
    "\n",
    "Extract relevant named entities, their relations and related information from this text. Think deep and analyze all information in the relevant text thoroughly. Try to infer relevant relationships between entities if not directly mentioned in the text.Finally Generate RDF turtle code that align with the ontology for the found entities and relationships. Make sure to give all entities relevant rdfs:label.\n",
    "\n",
    "{corpus}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Make a call to the OpenAI client\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    " ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=messages,\n",
    "    max_completion_tokens=20000,\n",
    "    reasoning_effort=\"high\"\n",
    " )\n",
    "\n",
    "# Print the response content\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why This Requires RDF and Formal Ontologies\n",
    "\n",
    "### The Limitations of Labeled Property Graphs (LPG)\n",
    "\n",
    "This ontology-driven extraction approach **cannot be replicated** with LPG databases like Neo4j for fundamental architectural reasons:\n",
    "\n",
    "### 1. **No Formal Ontologies**\n",
    "\n",
    "**LPG databases lack formal ontology support:**\n",
    "- Labels and relationship types are just **strings**, not semantically defined concepts\n",
    "- No formal class hierarchies (RDFS/OWL)\n",
    "- No property domain/range definitions\n",
    "- No reasoning or inference capabilities\n",
    "\n",
    "**Example:** In Neo4j, you might have:\n",
    "```cypher\n",
    "(:Jaguar {name: \"El Jefe\"})-[:OCCURS_IN]->(:Location {name: \"Arizona\"})\n",
    "```\n",
    "\n",
    "But the LLM has no formal structure to understand:\n",
    "- What a `Jaguar` node represents (could be a car, guitar, or animal)\n",
    "- What properties `Jaguar` should have\n",
    "- What relationships are valid\n",
    "- How concepts relate hierarchically\n",
    "\n",
    "### 2. **No Semantic Standards**\n",
    "\n",
    "**RDF provides W3C standards:**\n",
    "- **RDFS** (Resource Description Framework Schema) - defines classes, properties, hierarchies\n",
    "- **OWL** (Web Ontology Language) - enables reasoning and inference\n",
    "- **SHACL** - validates data shapes\n",
    "- **SKOS** - manages vocabularies and taxonomies\n",
    "\n",
    "**LPG has:**\n",
    "- Vendor-specific schemas (Neo4j, TigerGraph, etc.)\n",
    "- No formal semantics\n",
    "- No standardized reasoning\n",
    "- No interoperability guarantees\n",
    "\n",
    "### 3. **Knowledge Representation vs. Data Storage**\n",
    "\n",
    "| Aspect | RDF/SPARQL (Knowledge Graphs) | LPG (Neo4j, etc.) |\n",
    "|--------|-------------------------------|-------------------|\n",
    "| **Schema** | Formal ontologies (RDFS/OWL) | Informal schemas |\n",
    "| **Semantics** | Explicit, machine-readable | Implicit, application-level |\n",
    "| **Reasoning** | Built-in (RDFS/OWL inference) | Application-specific |\n",
    "| **Standards** | W3C standards (RDF, SPARQL) | Vendor-specific |\n",
    "| **Interoperability** | Universal (URIs, namespaces) | Limited |\n",
    "| **Open World** | Yes (absence ‚â† false) | No (closed world) |\n",
    "| **LLM Guidance** | Rich semantic structure | Just node/edge labels |\n",
    "\n",
    "### 4. **Why LLMs Need Ontologies**\n",
    "\n",
    "When extracting knowledge, the LLM requires:\n",
    "\n",
    "‚úÖ **With RDF Ontologies:**\n",
    "- Formal class definitions (`ont:Jaguar rdfs:subClassOf ont:Animal`)\n",
    "- Property domains and ranges (`ont:hasGender rdfs:domain ont:Jaguar ; rdfs:range xsd:string`)\n",
    "- Relationship semantics (`ont:monitoredByOrg rdfs:range ont:Organization`)\n",
    "- Hierarchical understanding (taxonomies)\n",
    "- Validation rules (cardinality, data types)\n",
    "\n",
    "‚ùå **With LPG:**\n",
    "- Just strings: `\"Jaguar\"`, `\"OCCURS_IN\"`, `\"Location\"`\n",
    "- No formal meaning\n",
    "- No hierarchical structure\n",
    "- No validation constraints\n",
    "- No way to distinguish domain concepts from noise\n",
    "\n",
    "### 5. **The \"Jaguar Problem\" Revisited**\n",
    "\n",
    "**Without formal ontologies**, an LLM extracting to LPG would:\n",
    "- Struggle to disambiguate jaguars (cars vs. animals)\n",
    "- Have no semantic guidance on valid properties\n",
    "- Create inconsistent graph structures\n",
    "- Require extensive post-processing and validation\n",
    "\n",
    "**With RDF ontologies**, the LLM:\n",
    "- Understands domain semantics from formal definitions\n",
    "- Generates semantically valid, structured data\n",
    "- Automatically filters irrelevant entities\n",
    "- Produces interoperable, standards-compliant knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion: Knowledge Graphs Enable Semantic AI\n",
    "\n",
    "This notebook demonstrates how **formal ontologies** (RDFS/OWL) transform LLMs from text processors into **semantic knowledge miners**. By grounding extraction in formal semantics, we achieve:\n",
    "\n",
    "- üéØ **Precision** - Extract only domain-relevant entities\n",
    "- üîó **Structure** - Generate properly connected knowledge graphs\n",
    "- üß† **Intelligence** - Enable reasoning and inference\n",
    "- üåê **Interoperability** - Create standards-compliant data\n",
    "- üîç **Queryability** - Support complex SPARQL queries\n",
    "\n",
    "**RDF + Ontologies + LLMs** = The future of intelligent knowledge extraction\n",
    "\n",
    "LPG databases are excellent for operational graph queries, but they fundamentally lack the **semantic infrastructure** required for ontology-driven knowledge representation. For true knowledge graphs that machines can understand and reason over, RDF and formal ontologies are essential.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
